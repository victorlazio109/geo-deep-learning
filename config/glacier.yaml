# Deep learning configuration file ------------------------------------------------
# Five sections :
#   1) Global parameters; those are re-used amongst the next three operations (sampling, training and inference)
#   2) Data analysis parameters
#   4) Sampling parameters
#   5) Training parameters
#   6) Inference parameters
#   7) Model parameters

# Global parameters

global:
  samples_size: 1024
  num_classes: 1
  data_path: /export/sata01/wspace/rgbn_test_runs/Atlass_Glacier/ # /wshare/travail/bdgrid2/EXTRACTION/Deep_learning/GDL_EAU_2019_20/cayouche/
  number_of_bands: 3
  model_name: unet_pretrained # One of unet, unetsmall, checkpointed_unet, ternausnet, fcn_resnet101, deeplabv3_resnet50,deeplabv3_resnet101
  task: segmentation  # Task to perform. Either segmentation or classification
  num_gpus: 1
  scale_data: [0,1]
  debug_mode: False
  BGR_to_RGB: False
  mlflow_uri: /export/sata01/wspace/mlflow/mlruns/

# Sample parameters; used in images_to_samples.py -------------------

sample:
  prep_csv_file: /export/sata01/wspace/rgbn_test_runs/Atlass_Glacier/glacier_atlas.csv
  val_percent: 5 # Percentage of validation samples created from train set (0 - 100)
  overlap: 0
  sampling_method:
    'min_annotated_percent': 0
  mask_reference: False


# Training parameters; used in train_segmentation.py ----------------------

training:
  state_dict_path: #/export/sata01/wspace/rgbn_test_runs/Atlass_Glacier/archive/samples1024_overlap0_min-annot0_3bands/model/glacier/_2021-05-20_08-32/checkpoint.pth.tar
  num_trn_samples:
  num_val_samples:
  num_tst_samples:
  batch_size: 2
  pretrained: True
  num_epochs: 100
  target_size: 512
  loss_fn: Dice # One of CrossEntropy, Lovasz, Focal, OhemCrossEntropy (*Lovasz for segmentation tasks only)
  optimizer: adam # One of adam, sgd or adabound
  learning_rate: 1e-4
  weight_decay: 1e-5
  step_size: 35
  gamma: 0.1
  class_weights: [0.223, 0.777]
  batch_metrics:   # (int) Metrics computed every (int) batches. If left blank, will not perform metrics. If (int)=1, metrics computed on all batches.
  ignore_index: -1 # Specifies a target value that is ignored and does not contribute to the input gradient. Default: None

  augmentation:
    rotate_limit: 90
    rotate_prob: 0.5
    hflip_prob: 0.5
    random_radiom_trim_range: # [0,0] # range of values (%) for trimming (same value used for left and right trim)

  normalization:
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]


# Inference parameters; used in inference.py --------

inference:
  img_dir_or_csv_file: /export/sata01/wspace/rgbn_test_runs/Atlass_Glacier/test/
  state_dict_path: /export/sata01/wspace/rgbn_test_runs/Atlass_Glacier/samples1024_overlap0_min-annot0_3bands/model/glacier/crossEntropy/checkpoint.pth.tar
  chunk_size: 2048
  ras2vec: True

# Visualization parameters

visualization:
  vis_batch_range: [0,10,1] #start, finish, increment
  vis_at_checkpoint: True
  vis_at_ckpt_min_ep_diff: 10
  vis_at_ckpt_dataset: val # FIXME: Parameter adds confusion. To be removed. Default to val dataset.
  vis_at_init: False
  vis_at_init_dataset: val
  vis_at_evaluation: True #val during training, tst at end of training
  vis_at_train: False
  grid: True
  heatmaps: False
  colormap_file: ./data/colormap.csv